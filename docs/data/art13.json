{
  "article": "13",
  "sheet": "GQs_Art.13",
  "requirement": "Art. 13: Transparency and Provision of Information to Deployers\n\nTrasversal Questions",
  "rows": [
    {
      "Compliance checklist": "1. The high-risk system is designed and developed with sufficient transparency to enable the appropriate use of the system and the interpretation of its output by deployers. The type and degree of transparency must ensure compliance with the obligations of the provider and deployer given in Section 3.",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.1     During the design phase of your system, did you explicitly address how deployers will interpret and act on outputs?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.2     Is your architecture interpretable-by-design or a blackbox?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.3    Considering the adopted architecture and intended context of use, what level of transparency does your application provide, and what are its main limitations?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.4    How do you define a sufficient and appropriate degree of transparency in your application?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.5     How did you validate your definition of “appropriate degree of transparency” with final deployers (i.e. recruiters)?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.6     Once you have defined the target transparency level, how do you implement it in code and/or UI?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.7     What is the output of your AI system? Is it represented by a single value (i.e., prediction score, ranking) or by a set of information (e.g., confidence scores, explanations)?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.8   Does the information provided by the AI system to ensure transparency and interpretability accurately reflect the algorithmic process that generated the output? How is the accuracy of this representation verified?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.9     Beyond built‑in transparency tools, what training materials, quick‑start guides, or “interpretation playbooks” do you provide to deployers?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.10     How do you verify that deployers correctly interpret the output of the AI system and use it appropriately within their decision-making process (e.g., post-deployment surveys)? In case of negative response, how do you correct the interpretability design?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.11     How and how often do you audit or test the interpretability of the AI system (e.g., A/B tests with varying information payload depths, simulated misuse scenarios)?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.12     How do you communicate to deployers (i) the residual opacity of the AI system and (ii) the limitations of the adopted interpretability techniques?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.13    Do you use techniques coming from Explainable AI literature to ensure an appropriate degree of transparency and interpretability of the outputs and of the process generating it?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     Which techniques do you use and why?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     How do you ensure that those techniques give consistent interpretations?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.14     Do you provide deployers with interpretability tools to correctly interpret both the the job-matching score (i.e., intermediate output in the AI architecture) and the relative ranking given by scores on different individuals (i.e., final output)?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.1.15 In case of candidates whose scores cannot be differentiate in a statistical significant manner, how is this information communicated to deployers?",
        }
      ]
    },
    {
      "Compliance checklist": "2. Appropriate instructions to use the high-risk system are provided in an appropriate digital format or otherwise, to achieve compliance with the relevant obligations. These instructions are concise, complete, correct and clear as well as relevant, accessible and comprehensible to deployers.",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.2.1     In which format are the instructions for use provided to deployers? And what is their content?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     Which information is provided to interpret the output of the system in order to ensure transparency of the AI application?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.2.2     What level of AI literacy is required to understand the provided instructions for use?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.2.3     Did you receive feedback from deployers about the quality of the instruction for use (i.e. are such information concise, complete, correct, clear, relevant, accessible and comprehensible)?",
        }
      ]
    },
    {
      "Compliance checklist": "3.  The instructions for use shall contain at least the following information:",
      "Guiding Questions": "",
      "_children": []
    },
    {
      "Compliance checklist": "3(a) the identity and the contact details of the provider and, where applicable, of its authorised representative",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.a.1    Are the identity and contact details of the provider included in the instructions given alongside your application?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.a.2     If applicable in your application, are the identity and contact details of the authorised representative of the provider given in the instructions?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.a.3     Does the instructions for use contain the identity and the contact details of the upstream provider in the case of integration of a third-party model? If not, why?",
        }
      ]
    },
    {
      "Compliance checklist": "3(b) the characteristics, capabilities and limitations of performance of the high-risk AI system, including:",
      "Guiding Questions": "",
      "_children": []
    },
    {
      "Compliance checklist": "3(b)(i) the intended purpose of the high-risk AI system.",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.1     Do the instructions include the intended purpose of the system?",
        }
      ]
    },
    {
      "Compliance checklist": "3(b)(ii) the level of accuracy, including its metrics, robustness and cybersecurity referred to in Article 15 against which the high-risk AI system has been tested and validated and which can be expected, and any known and foreseeable circumstances that may have an impact on that expected level of accuracy, robustness and cybersecurity;",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.2     Do the instructions include the level of accuracy of your system, including the metrics, robustness and cybersecurity, against which your system has been tested and validated?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.3     Do the instructions include any known and foreseeable circumstances that may affect the level of accuracy, robustness and cybersecurity?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.4     Do your instructions state and justify any problem and limitations in defining metrics regarding accuracy, robustness and cybersecurity in the test or validation phase?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.5    Do your instructions include some guidelines on how to handle foreseeable and/or unforeseeable drops in the level of accuracy, robustness and cybersecurity?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     What is the expected workload for the implementation of these guidelines? For example, low effort would indicate that every deployer can perform the operations induced by the guidelines. Justify your assumptions about the workload.",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     Did you previously verify with your deployer that these guidelines are actionable?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.6 Is there an update mechanism to add unforeseen circumstances in the instruction for use after they have been identified in deployment?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "[For completeness, Please Refer to Art.15]",
        }
      ]
    },
    {
      "Compliance checklist": "3(b)(iii) known or foreseeable circumstances related to the use of the high-risk AI system  according to the intended purpose or reasonably foreseeable misuse which may lead to health, safety, or fundamental right risks (Article 9(2));",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.7     Do the instructions include any known or foreseeable circumstance which may lead to risks to the health and safety or fundamental rights",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     related to the use of your AI system based on the intended purpose?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     related to the reasonably foreseeable misuse of your system?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.8 For each of the known and foreseeable circumstances which may lead to risks to the health and safety or fundamental rights, do you have an explicit plan on how to handle them?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.9 Given the context of use, does your instruction for use contain guidelines on how to handle input data which is not comparable with the one on which it has been tested and validated (e.g. in terms of sensitive attributes)?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "[For completeness, Please Refer to Art.9 (2) and Refer to Guiding Questions Art.10.2(f-g)]",
        }
      ]
    },
    {
      "Compliance checklist": "3(b)(iv) where applicable, the technical capabilities of the system to provide information to explain its output;",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.10     Does the instruction for use include the technical capabilities and limitations for the AI system to explain this output (e.g. Explainable AI techniques)?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.11 Does the document contain instructions on how to intepret and comprehend the output of the System (e.g. how to interpret different visualizations given by the interpretability techniques used)?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.12     If not included, why do you think it is not applicable to your context of use?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.13     If not included, what are the foreseeable consequences on an appropriate human oversight (Art.14)?",
        }
      ]
    },
    {
      "Compliance checklist": "3(b)(v) when appropriate, the performance of the system regarding specific persons or groups of persons on which the system is intended to be used;",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.14     If appropriate in your application, do the instructions include the performance of your system regarding specific persons or groups of persons on which the system is intended to be used?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.15  If not appropriate did you state it in the instruction of use?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.16 Does the instruction for use detail the means of communication in which the deployer will be informed in the case of a curriculum processing that does not belong to the group of persons for which the Systems has been tested and validated?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.17 Does your instruction for use detail what to do in case of a curriculum processing that does not belong to the group of persons for which the system is tested and validated?",
        }
      ]
    },
    {
      "Compliance checklist": "3(b)(vi) when appropriate, specifications for the input data, or any other relevant information in terms of the [training], validation and testing data sets used, taking into account the intended purpose of the high-risk AI system;",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.18     If appropriate, do the instructions cover the characteristics, capabilities, and limitations of your input data, validation, and testing data, based on the system’s intended purpose?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.19 Does the instruction for use contain information about the modalities of input data that can be processed by the AI System (e.g. text, images, video and combinations thereof)?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.20 Does the instruction for use contain specifications about different characters sets of textual input data (e.g. latin alphabet, greek script, cyrillic, chinese)?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.21 Does the instruction for use contain limitations about the input data formats (e.g. document layout and length and video formats)?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.22 Does the instruction for use contain limitations of the quantity and representativeness of the input data in terms of special categories of personal data?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.23     If not included, why do you think it is not appropriate for your context of use?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "[Please Refer to Art. 10]",
        }
      ]
    },
    {
      "Compliance checklist": "3(b)(vii) where applicable, the information to enable the deployers to interpret the output of the high-risk AI system and to use it appropriately.",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.b.24    If applicable to your application, do the instructions include information for interpreting the output of the system and to using it appropriately by deployers?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○      If not applicable, justify why.",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "[Please Refer to Guiding Questions Art.13.1 and document them in the Instruction for use. If not applicable justify your motivations.]",
        }
      ]
    },
    {
      "Compliance checklist": "3.  The instructions for use shall contain at least the following information:",
      "Guiding Questions": "",
      "_children": []
    },
    {
      "Compliance checklist": "3(c). the changes to the high-risk AI system and its performance which have been predetermined by the provider at the moment of the initial conformity assessment, if any;",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.c.1     Are there any changes to your AI system which are predetermined by the provider at the moment of initial conformity assessment?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     If yes, are these changes and the predetermined performances included in the instructions?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     Does the instruction include and fully state how the provider and the deployer should interact with the system after (or in the meantime) such changes have been made?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     Does the instruction for use contain information about how performance and fairness assessments will be impacted by the implementation of predetermined bias mitigation techniques not yet in place at the time of initial conformity assessment?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     Does the instruction for use contain information on performance changes when additional CV languages support is added (predetermined but not yet in place at the time of initial conformity assessment)?",
        }
      ]
    },
    {
      "Compliance checklist": "3(d). human oversight measures including technical measures to facilitate the interpretation of the output of the AI system by deployers (Article 14).",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.d.1     Do the instructions include human oversight measures? Describe them.",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.d.2     Do the instructions include the technical measures to facilitate the interpretation of the output by deployers? Describe them.",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.d.3    Do you address the problem of “interpretability” (or comprehensibility, legibility) of the output by the deployers?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.d.4 Does the instruction for use include information on the technical measures implemented to verify the faithfulness and robustness of interpretability techniques in supporting the interpretation of the system’s output?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.d.5 Does the instruction for use provide guidance on how to interpret results in cases where candidate scores are nearly identical, particularly to support the recognition of nuanced distinctions among them?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "[For completeness, please Refer to guiding questions in Art.14 and document accordingly]",
        }
      ]
    },
    {
      "Compliance checklist": "3(e). the needed computational and hardware resource specifications, the expected lifetime of the system, maintenance and care measures, including software updates, and their frequency.",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.e.1     Do the instructions include the needed hardware specifications?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.e.2     Do the instructions include maintenance and care measures, including software updates, and their frequency?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.e.3 Do the instructions include the minimal hardware requirements that the deployer would need in order to use the AI system appropriately?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.e.4 Do the instructions include the expected lifetime of the AI system and what to do after the expiration date?",
        }
      ]
    },
    {
      "Compliance checklist": "3(f). If relevant, instructions include the description of the mechanisms included within the high-risk AI system that allows deployers to properly collect, store and interpret the logs (Art.12).",
      "Guiding Questions": "",
      "_children": [
        {
          "Compliance checklist": "",
          "Guiding Questions": "13.3.f.1     Does your high-risk AI system allow deployers to collect, store and interpret logs?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     If yes, do the instructions include a description of mechanisms regarding these?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "○     If yes, are logs written in a legible way?",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "[For completeness, please refer to Art.12]",
        },
        {
          "Compliance checklist": "",
          "Guiding Questions": "If the AI system has been developed by integrating GPAI models, what transparency measures have been adopted, taking into account the specific characteristics of such models? What technical measures and contractual safeguards have been put in place?",
        }
      ]
    }
  ]
}